{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pwCuAr2iCdNl"},"outputs":[],"source":["!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lrO4Nn3yFbhn"},"outputs":[],"source":["!pip install evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["44c8e961cc304c49b57f5766bd68f0ce","8113e2d123ea40cb81c726b023f5f360","b7e12c8668184df7ad7404dc2bbdd040","6310b4f365c04767924d385df3f6f84d","9f184a67fb854b079b54c9795b0dbc50","d5c1f11517a041549896754f49043871","3d692133ad684a738d13b8bfc5aae124","545e135a148641ae9d717b0d1e5b3b4a","ef9790e6aecc4c559b53f2211d31fbbb","d72a7b5a05254acb9cd5e1906b2bca77","e8312066091e43138bac603ff79edc72"]},"executionInfo":{"elapsed":1514,"status":"ok","timestamp":1728407106218,"user":{"displayName":"Sahil Pahapale","userId":"12774672475127564247"},"user_tz":-330},"id":"J5lIsY91FeyO","outputId":"10381a94-8a21-408f-81e2-63c7d9d4af2f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44c8e961cc304c49b57f5766bd68f0ce","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import evaluate\n","metric = evaluate.load('accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":428,"status":"ok","timestamp":1728408377105,"user":{"displayName":"Sahil Pahapale","userId":"12774672475127564247"},"user_tz":-330},"id":"gW-DCKXKECtM","outputId":"064e0f21-8ba0-48c6-f8b0-ae6b0d6f5f62"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import pipeline, set_seed\n","import matplotlib.pyplot as plt\n","from datasets import load_dataset\n","import pandas as pd\n","\n","from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","\n","from tqdm import tqdm\n","import tensorflow as tf\n","nltk.download(\"punkt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3536,"status":"ok","timestamp":1728408219926,"user":{"displayName":"Sahil Pahapale","userId":"12774672475127564247"},"user_tz":-330},"id":"knFnw1cZE-PH","outputId":"06e7233a-e1f3-4bf3-ff23-1432d6a3c81b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["model = \"google/pegasus-large\"\n","tockenizer = AutoTokenizer.from_pretrained(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122,"referenced_widgets":["27d759b941544881a26534dc6751b13b","1605f0fb0c02473386be5985ebbeb372","1184349c603f4e7baf707284002d05e7","53444c5985d044fe833ac164782c7313","63ac7977aa9644cb835d580e01196e6c","b041e5310cfb40738f0057fbfd2e33dd","b29dc680c7254704bbf42b26e18f92bb","9417a92018b24ae18b0e687147dbd31b","474816e73d544b2a969fcd4864589253","b352af3d7ba64f6dabfce293316eb75f","99afba1f352a45bd9c9394875ce2b45e"]},"executionInfo":{"elapsed":53358,"status":"ok","timestamp":1728408276027,"user":{"displayName":"Sahil Pahapale","userId":"12774672475127564247"},"user_tz":-330},"id":"bfjjmSYwIkxV","outputId":"c01b056f-380d-4493-f76a-1f3a5374efa4"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27d759b941544881a26534dc6751b13b","version_major":2,"version_minor":0},"text/plain":["tf_model.h5:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFPegasusForConditionalGeneration.\n","\n","Some layers of TFPegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['final_logits_bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model_pegasus = TFAutoModelForSeq2SeqLM.from_pretrained(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rok8O-gvOYiL"},"outputs":[],"source":["def generate_batch_sized_chunks(list_of_elements, batch_size):\n","    \"\"\"split the dataset into smaller batches that we can process simultaneously\n","    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n","    for i in range(0, len(list_of_elements), batch_size):\n","        yield list_of_elements[i : i + batch_size]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rNfD8px2Tz5E"},"outputs":[],"source":["from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n","import tensorflow as tf\n","from tqdm import tqdm\n","\n","def calculate_metric_on_test_ds_tf(dataset, metric, model, tokenizer,\n","                                  batch_size=16, device='auto',\n","                                  column_text=\"article\",\n","                                  column_summary=\"highlights\"):\n","    device = '/gpu:0' if tf.config.list_physical_devices('GPU') and device == 'auto' else '/cpu:0'\n","\n","    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n","    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n","\n","    with tf.device(device):\n","        for article_batch, target_batch in tqdm(\n","            zip(article_batches, target_batches), total=len(article_batches)):\n","\n","\n","            inputs = tokenizer(article_batch, max_length=1024, truncation=True,\n","                               padding=\"max_length\", return_tensors=\"tf\")\n","\n","            summaries = model.generate(input_ids=inputs[\"input_ids\"],\n","                                       attention_mask=inputs[\"attention_mask\"],\n","                                       length_penalty=0.8, num_beams=8, max_length=128)\n","\n","            decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n","                                                  clean_up_tokenization_spaces=True)\n","                                 for s in summaries]\n","\n","            decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n","\n","            metric.add_batch(predictions=decoded_summaries, references=target_batch)\n","\n","    score = metric.compute()\n","    return score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2588,"status":"ok","timestamp":1728410887969,"user":{"displayName":"Sahil Pahapale","userId":"12774672475127564247"},"user_tz":-330},"id":"JQWnWPVpT3q5","outputId":"837b0e0b-c68c-4425-b323-f6904b3b18c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Split lengths: [14732, 819, 818]\n","Features: ['id', 'dialogue', 'summary']\n","\n","Dialogue:\n","Eric: MACHINE!\r\n","Rob: That's so gr8!\r\n","Eric: I know! And shows how Americans see Russian ;)\r\n","Rob: And it's really funny!\r\n","Eric: I know! I especially like the train part!\r\n","Rob: Hahaha! No one talks to the machine like that!\r\n","Eric: Is this his only stand-up?\r\n","Rob: Idk. I'll check.\r\n","Eric: Sure.\r\n","Rob: Turns out no! There are some of his stand-ups on youtube.\r\n","Eric: Gr8! I'll watch them now!\r\n","Rob: Me too!\r\n","Eric: MACHINE!\r\n","Rob: MACHINE!\r\n","Eric: TTYL?\r\n","Rob: Sure :)\n","\n","Summary:\n","Eric and Rob are going to watch a stand-up on youtube.\n"]}],"source":["dataset_samsum = load_dataset(\"samsum\")\n","\n","split_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n","\n","print(f\"Split lengths: {split_lengths}\")\n","print(f\"Features: {dataset_samsum['train'].column_names}\")\n","print(\"\\nDialogue:\")\n","\n","print(dataset_samsum[\"test\"][1][\"dialogue\"])\n","\n","print(\"\\nSummary:\")\n","\n","print(dataset_samsum[\"test\"][1][\"summary\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"elapsed":388,"status":"ok","timestamp":1728410901263,"user":{"displayName":"Sahil Pahapale","userId":"12774672475127564247"},"user_tz":-330},"id":"JA_DIdYYURqs","outputId":"d7006dfa-e789-4703-9cb1-68e94fb655bb"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Hannah: Hey, do you have Betty's number?\\nAmanda: Lemme check\\nHannah: <file_gif>\\nAmanda: Sorry, can't find it.\\nAmanda: Ask Larry\\nAmanda: He called her last time we were at the park together\\nHannah: I don't know him well\\nHannah: <file_gif>\\nAmanda: Don't be shy, he's very nice\\nHannah: If you say so..\\nHannah: I'd rather you texted him\\nAmanda: Just text him ðŸ™‚\\nHannah: Urgh.. Alright\\nHannah: Bye\\nAmanda: Bye bye\""]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["dataset_samsum['test'][0]['dialogue']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66782,"status":"ok","timestamp":1728410989789,"user":{"displayName":"Sahil Pahapale","userId":"12774672475127564247"},"user_tz":-330},"id":"0_XNFLn0UVcx","outputId":"ae5d66af-aea0-40a4-f319-b37d16b8afbb"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Your max_length is set to 256, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"]},{"name":"stdout","output_type":"stream","text":["[{'summary_text': \"Amanda: Ask Larry Amanda: He called her last time we were at the park together Hannah: I don't know him well Hannah: file_gif> Amanda: Don't be shy, he's very nice Hannah: If you say so..\"}]\n"]}],"source":["pipe = pipeline('summarization', model = model )\n","\n","pipe_out = pipe(dataset_samsum['test'][0]['dialogue'] )\n","\n","print(pipe_out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vmRVyPYHfGq-"},"outputs":[],"source":["import evaluate\n","\n","rouge_metric = evaluate.load('rouge')\n","\n","score = calculate_metric_on_test_ds_tf(dataset_samsum['test'], rouge_metric, model_pegasus, tockenizer, column_text='dialogue', column_summary='summary', batch_size=8)\n","\n","print(score)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fqim53ETUr_a"},"outputs":[],"source":["rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n","rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n","\n","pd.DataFrame(rouge_dict, index = ['pegasus'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wguGnAT1Vqiq"},"outputs":[],"source":["dialogue_token_len = len([tokenizer.encode(s) for s in dataset_samsum['train']['dialogue']])\n","\n","summary_token_len = len([tokenizer.encode(s) for s in dataset_samsum['train']['summary']])\n","\n","\n","fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n","axes[0].hist(dialogue_token_len, bins = 20, color = 'C0', edgecolor = 'C0' )\n","axes[0].set_title(\"Dialogue Token Length\")\n","axes[0].set_xlabel(\"Length\")\n","axes[0].set_ylabel(\"Count\")\n","\n","axes[1].hist(summary_token_len, bins = 20, color = 'C0', edgecolor = 'C0' )\n","axes[1].set_title(\"Summary Token Length\")\n","axes[1].set_xlabel(\"Length\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33ua5F9dVqlm"},"outputs":[],"source":["def convert_examples_to_features(example_batch):\n","    input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n","\n","    with tokenizer.as_target_tokenizer():\n","        target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n","\n","    return {\n","        'input_ids' : input_encodings['input_ids'],\n","        'attention_mask': input_encodings['attention_mask'],\n","        'labels': target_encodings['input_ids']\n","    }\n","\n","dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLh6osfQVqoW"},"outputs":[],"source":["from transformers import DataCollatorForSeq2Seq\n","\n","seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jsrxSxNJVqq2"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","\n","trainer_args = TrainingArguments(\n","    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n","    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n","    weight_decay=0.01, logging_steps=10,\n","    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n","    gradient_accumulation_steps=16\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"chBsqDw1VqtI"},"outputs":[],"source":["trainer = Trainer(model=model_pegasus, args=trainer_args,\n","                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n","                  train_dataset=dataset_samsum_pt[\"train\"],\n","                  eval_dataset=dataset_samsum_pt[\"validation\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v0T_OXrfV0So"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RdWwuuwjV0Vl"},"outputs":[],"source":["score = calculate_metric_on_test_ds(\n","    dataset_samsum['test'], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n",")\n","\n","rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n","\n","pd.DataFrame(rouge_dict, index = [f'pegasus'] )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"glLwUSrgV0YO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gSIVkHiLV0ao"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPzPJG/fm5rHxSaPojKjS4W","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"lg","language":"python","name":"lg"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1184349c603f4e7baf707284002d05e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9417a92018b24ae18b0e687147dbd31b","max":2283889512,"min":0,"orientation":"horizontal","style":"IPY_MODEL_474816e73d544b2a969fcd4864589253","value":2283889512}},"1605f0fb0c02473386be5985ebbeb372":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b041e5310cfb40738f0057fbfd2e33dd","placeholder":"â€‹","style":"IPY_MODEL_b29dc680c7254704bbf42b26e18f92bb","value":"tf_model.h5:â€‡100%"}},"27d759b941544881a26534dc6751b13b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1605f0fb0c02473386be5985ebbeb372","IPY_MODEL_1184349c603f4e7baf707284002d05e7","IPY_MODEL_53444c5985d044fe833ac164782c7313"],"layout":"IPY_MODEL_63ac7977aa9644cb835d580e01196e6c"}},"3d692133ad684a738d13b8bfc5aae124":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44c8e961cc304c49b57f5766bd68f0ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8113e2d123ea40cb81c726b023f5f360","IPY_MODEL_b7e12c8668184df7ad7404dc2bbdd040","IPY_MODEL_6310b4f365c04767924d385df3f6f84d"],"layout":"IPY_MODEL_9f184a67fb854b079b54c9795b0dbc50"}},"474816e73d544b2a969fcd4864589253":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53444c5985d044fe833ac164782c7313":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b352af3d7ba64f6dabfce293316eb75f","placeholder":"â€‹","style":"IPY_MODEL_99afba1f352a45bd9c9394875ce2b45e","value":"â€‡2.28G/2.28Gâ€‡[00:24&lt;00:00,â€‡31.4MB/s]"}},"545e135a148641ae9d717b0d1e5b3b4a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6310b4f365c04767924d385df3f6f84d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d72a7b5a05254acb9cd5e1906b2bca77","placeholder":"â€‹","style":"IPY_MODEL_e8312066091e43138bac603ff79edc72","value":"â€‡4.20k/4.20kâ€‡[00:00&lt;00:00,â€‡50.6kB/s]"}},"63ac7977aa9644cb835d580e01196e6c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8113e2d123ea40cb81c726b023f5f360":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5c1f11517a041549896754f49043871","placeholder":"â€‹","style":"IPY_MODEL_3d692133ad684a738d13b8bfc5aae124","value":"Downloadingâ€‡builderâ€‡script:â€‡100%"}},"9417a92018b24ae18b0e687147dbd31b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99afba1f352a45bd9c9394875ce2b45e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f184a67fb854b079b54c9795b0dbc50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b041e5310cfb40738f0057fbfd2e33dd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b29dc680c7254704bbf42b26e18f92bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b352af3d7ba64f6dabfce293316eb75f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7e12c8668184df7ad7404dc2bbdd040":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_545e135a148641ae9d717b0d1e5b3b4a","max":4203,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef9790e6aecc4c559b53f2211d31fbbb","value":4203}},"d5c1f11517a041549896754f49043871":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d72a7b5a05254acb9cd5e1906b2bca77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8312066091e43138bac603ff79edc72":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef9790e6aecc4c559b53f2211d31fbbb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
